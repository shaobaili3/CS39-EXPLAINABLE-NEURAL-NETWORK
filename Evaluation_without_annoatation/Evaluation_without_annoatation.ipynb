{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path\n",
    "import spacy\n",
    "import sklearn.model_selection\n",
    "import numpy as np\n",
    "import lime\n",
    "from lime import discretize\n",
    "from anchor import anchor_text\n",
    "from tqdm import tqdm\n",
    "nlp = spacy.load('C:\\\\Users\\\\EZEE\\\\Desktop\\\\schools\\\\capstone\\\\anchor and lime\\\\en_core_web_lg\\\\en_core_web_lg-2.2.5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "10hLmgCTU5gt"
   },
   "outputs": [],
   "source": [
    "def load_polarity(path='C:\\\\Users\\\\EZEE\\\\Desktop\\\\schools\\\\capstone\\\\anchor and lime'):\n",
    "    data = []\n",
    "    labels = []\n",
    "    f_names = ['rt-polarity.neg', 'rt-polarity.pos']\n",
    "    for (l, f) in enumerate(f_names):\n",
    "        for line in open(os.path.join(path, f), 'rb'):\n",
    "            try:\n",
    "                line.decode('utf8')\n",
    "            except:\n",
    "                continue\n",
    "            data.append(line.strip())\n",
    "            labels.append(l)\n",
    "    return data, labels\n",
    "\n",
    "data, labels = load_polarity()\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_tr, x_te, y_train, y_test = train_test_split(data, labels, test_size=0.33, random_state=42, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1998,
     "status": "ok",
     "timestamp": 1590576349352,
     "user": {
      "displayName": "EZEE MA",
      "photoUrl": "",
      "userId": "17914780779946211373"
     },
     "user_tz": -600
    },
    "id": "HQMA1oaOV1Wb",
    "outputId": "322af418-dccd-40b6-8ee7-fb1c2a8fa92b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\EZEE\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\EZEE\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "import re\n",
    "from nltk.corpus import stopwords as sw\n",
    "import itertools\n",
    "from nltk.stem.porter import *\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import itertools\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "\n",
    "#This block define a function 'expandContractions' that expan the short hand variant to it's base form. for example \"I'm\" -> 'i am'.\n",
    "\n",
    "#define the constraction dictionary\n",
    "contraction_dict = {\"ain't\": \"is not\", \"aren't\": \"are not\",\"can't\": \"cannot\", \"'cause\": \"because\", \"could've\": \"could have\", \n",
    "                    \"couldn't\": \"could not\", \"didn't\": \"did not\",  \"doesn't\": \"does not\", \"don't\": \"do not\", \"hadn't\": \"had not\", \n",
    "                    \"hasn't\": \"has not\", \"haven't\": \"have not\", \"he'd\": \"he would\",\"he'll\": \"he will\", \"he's\": \"he is\", \"how'd\": \"how did\", \n",
    "                    \"how'd'y\": \"how do you\", \"how'll\": \"how will\", \"how's\": \"how is\",  \"I'd\": \"I would\", \"I'd've\": \"I would have\", \n",
    "                    \"I'll\": \"I will\", \"I'll've\": \"I will have\",\"I'm\": \"I am\", \"I've\": \"I have\", \"i'd\": \"i would\", \"i'd've\": \"i would have\", \n",
    "                    \"i'll\": \"i will\",  \"i'll've\": \"i will have\",\"i'm\": \"i am\", \"i've\": \"i have\", \"isn't\": \"is not\", \"it'd\": \"it would\", \n",
    "                    \"it'd've\": \"it would have\", \"it'll\": \"it will\", \"it'll've\": \"it will have\",\"it's\": \"it is\", \"let's\": \"let us\", \n",
    "                    \"ma'am\": \"madam\", \"mayn't\": \"may not\", \"might've\": \"might have\",\"mightn't\": \"might not\",\"mightn't've\": \"might not have\", \n",
    "                    \"must've\": \"must have\", \"mustn't\": \"must not\", \"mustn't've\": \"must not have\", \"needn't\": \"need not\", \"needn't've\": \"need not have\",\n",
    "                    \"o'clock\": \"of the clock\", \"oughtn't\": \"ought not\", \"oughtn't've\": \"ought not have\", \"shan't\": \"shall not\", \"sha'n't\": \"shall not\", \n",
    "                    \"shan't've\": \"shall not have\", \"she'd\": \"she would\", \"she'd've\": \"she would have\", \"she'll\": \"she will\", \"she'll've\": \"she will have\", \n",
    "                    \"she's\": \"she is\", \"should've\": \"should have\", \"shouldn't\": \"should not\", \"shouldn't've\": \"should not have\", \"so've\": \"so have\",\n",
    "                    \"so's\": \"so as\", \"this's\": \"this is\",\"that'd\": \"that would\", \"that'd've\": \"that would have\", \"that's\": \"that is\", \"there'd\": \"there would\", \n",
    "                    \"there'd've\": \"there would have\", \"there's\": \"there is\", \"here's\": \"here is\",\"they'd\": \"they would\", \"they'd've\": \"they would have\", \n",
    "                    \"they'll\": \"they will\", \"they'll've\": \"they will have\", \"they're\": \"they are\", \"they've\": \"they have\", \"to've\": \"to have\", \"wasn't\": \"was not\", \n",
    "                    \"we'd\": \"we would\", \"we'd've\": \"we would have\", \"we'll\": \"we will\", \"we'll've\": \"we will have\", \"we're\": \"we are\", \"we've\": \"we have\", \n",
    "                    \"weren't\": \"were not\", \"what'll\": \"what will\", \"what'll've\": \"what will have\", \"what're\": \"what are\",  \"what's\": \"what is\", \"what've\": \"what have\", \n",
    "                    \"when's\": \"when is\", \"when've\": \"when have\", \"where'd\": \"where did\", \"where's\": \"where is\", \"where've\": \"where have\", \"who'll\": \"who will\", \n",
    "                    \"who'll've\": \"who will have\", \"who's\": \"who is\", \"who've\": \"who have\", \"why's\": \"why is\", \"why've\": \"why have\", \"will've\": \"will have\", \n",
    "                    \"won't\": \"will not\", \"won't've\": \"will not have\", \"would've\": \"would have\", \"wouldn't\": \"would not\", \"wouldn't've\": \"would not have\", \n",
    "                    \"y'all\": \"you all\", \"y'all'd\": \"you all would\",\"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\"y'all've\": \"you all have\",\n",
    "                    \"you'd\": \"you would\", \"you'd've\": \"you would have\", \"you'll\": \"you will\", \"you'll've\": \"you will have\", \"you're\": \"you are\", \"you've\": \"you have\"}\n",
    "\n",
    "c_re = re.compile('(%s)' % '|'.join(contraction_dict.keys()))\n",
    "\n",
    "def expandContractions(text, c_re=c_re):\n",
    "    def replace(match):\n",
    "        return contraction_dict[match.group(0)]\n",
    "    return c_re.sub(replace, text.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fmg2VxsUV2MU"
   },
   "outputs": [],
   "source": [
    "def clean_sentence(text):\n",
    "    clean_text = []\n",
    "    for corpus in text:\n",
    "        #print(corpus)\n",
    "        if type(corpus) is bytes:\n",
    "            corpus = corpus.decode('utf-8')\n",
    "        #chnage word to lower case, we want to ignore capital or lower cases\n",
    "        lower_doc = corpus.lower()\n",
    " \n",
    "        #expan construction of words into it's full representation\n",
    "        expand_doc = expandContractions(lower_doc)\n",
    "        \n",
    "        #delete punctuation\n",
    "        clean_doc = re.sub(r'[^\\w\\s]','',expand_doc)\n",
    "        \n",
    "        #split sentence into words\n",
    "        tokenized_doc1 = word_tokenize(clean_doc)\n",
    "        \n",
    "        sww = sw.words() \n",
    "        new_corpus = [w for w in tokenized_doc1 if not w in sww]\n",
    "        clean_text.append(new_corpus)\n",
    "    return clean_text\n",
    "\n",
    "x_train = clean_sentence(x_tr)\n",
    "x_test = clean_sentence(x_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 39952,
     "status": "ok",
     "timestamp": 1590576390220,
     "user": {
      "displayName": "EZEE MA",
      "photoUrl": "",
      "userId": "17914780779946211373"
     },
     "user_tz": -600
    },
    "id": "vgQ7kZ7yVA3x",
    "outputId": "2ef0ed5c-5be2-40ed-95ce-2d3b72b4ce7d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19387"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_data = x_train + x_test\n",
    "word_to_ix = {}\n",
    "for sentence in clean_data:\n",
    "    for word in sentence:\n",
    "        word = word.lower()\n",
    "        if word not in word_to_ix:\n",
    "            word_to_ix[word] = len(word_to_ix)\n",
    "word_list = list(word_to_ix.keys())\n",
    "word_list += ['unk']\n",
    "word_to_ix['unk'] = len(word_to_ix)\n",
    "word_to_ix['unk']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 98823,
     "status": "ok",
     "timestamp": 1590576449940,
     "user": {
      "displayName": "EZEE MA",
      "photoUrl": "",
      "userId": "17914780779946211373"
     },
     "user_tz": -600
    },
    "id": "_s8FtPBMVrWM",
    "outputId": "1e10a418-7dc3-42bb-b9cb-c93099dfb42c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\EZEE\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:9: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(19388, 50)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gensim.downloader as api\n",
    "word_emb_model = api.load(\"glove-twitter-50\") \n",
    "\n",
    "EMBEDDING_DIM = 50\n",
    "\n",
    "embedding_matrix = []\n",
    "for word in word_list:\n",
    "    try:\n",
    "        embedding_matrix.append(word_emb_model.wv[word])\n",
    "    except:\n",
    "        embedding_matrix.append([0]*EMBEDDING_DIM)\n",
    "embedding_matrix = np.array(embedding_matrix)\n",
    "embedding_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "agLZm7HqY7ka"
   },
   "outputs": [],
   "source": [
    "def to_index(data, to_ix):\n",
    "    input_index_list = []\n",
    "    for sent in data:\n",
    "        input_index_list.append([to_ix[w] for w in sent])\n",
    "    return input_index_list\n",
    "\n",
    "train_input_index =  to_index(x_train,word_to_ix)\n",
    "train_output_index = y_train\n",
    "val_input_index = to_index(x_test,word_to_ix)\n",
    "val_output_index = y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "buhGc4sWt7RL"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch.nn import functional as F\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch.nn import functional as F\n",
    "\n",
    "class SelfAttention(nn.Module):\n",
    "    def __init__(self, batch_size, output_size, hidden_size, vocab_size, embedding_length):\n",
    "        super(SelfAttention, self).__init__()\n",
    "        self.batch_size = batch_size\n",
    "        self.output_size = output_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embedding_length = embedding_length\n",
    "\n",
    "        self.word_embeddings = nn.Embedding(vocab_size, embedding_length)\n",
    "        self.word_embeddings.weight.data.copy_(torch.from_numpy(embedding_matrix))\n",
    "\n",
    "        self.dropout = 0.3\n",
    "        self.bilstm = nn.LSTM(embedding_length, hidden_size, dropout=self.dropout, bidirectional=True)\n",
    "        # We will use da = 350, r = 30 & penalization_coeff = 1 as per given in the self-attention original ICLR paper\n",
    "        self.W_s1 = nn.Linear(2*hidden_size, 350)\n",
    "        self.W_s2 = nn.Linear(350, 30)\n",
    "        self.fc_layer = nn.Linear(30*2*hidden_size, 2000)\n",
    "        self.label = nn.Linear(2000, output_size)\n",
    "  \n",
    "    def attention_net(self, lstm_output):\n",
    "        attn_weight_matrix = self.W_s2(F.tanh(self.W_s1(lstm_output)))\n",
    "        attn_weight_matrix = attn_weight_matrix.permute(0, 2, 1)\n",
    "        attn_weight_matrix = F.softmax(attn_weight_matrix, dim=2)\n",
    "        return attn_weight_matrix\n",
    "\n",
    "    def forward(self, input_sentences, batch_size=None):\n",
    "        input = self.word_embeddings(input_sentences).view(len(input_sentences), 1, -1)\n",
    "        if batch_size is None:\n",
    "    \n",
    "            h_0 = Variable(torch.zeros(2, 1, self.hidden_size).cuda())\n",
    "            c_0 = Variable(torch.zeros(2, 1, self.hidden_size).cuda())\n",
    "        else:\n",
    "            h_0 = Variable(torch.zeros(2, batch_size, self.hidden_size).cuda())\n",
    "            c_0 = Variable(torch.zeros(2, batch_size, self.hidden_size).cuda())\n",
    "\n",
    "        output, (h_n, c_n) = self.bilstm(input, (h_0, c_0))\n",
    "        output = output.permute(1, 0, 2)\n",
    "        # output.size() = (batch_size, num_seq, 2*hidden_size)\n",
    "        # h_n.size() = (1, batch_size, hidden_size)\n",
    "        # c_n.size() = (1, batch_size, hidden_size)\n",
    "        attn_weight_matrix = self.attention_net(output)\n",
    "        #print(attn_weight_matrix)\n",
    "        # output.size() = (batch_size, num_seq, 2*hidden_size)\n",
    "        hidden_matrix = torch.bmm(attn_weight_matrix, output)\n",
    "        # hidden_matrix.size() = (batch_size, r, 2*hidden_size)\n",
    "        # Let's now concatenate the hidden_matrix and connect it to the fully connected layer.\n",
    "        fc_out = self.fc_layer(hidden_matrix.view(-1, hidden_matrix.size()[1]*hidden_matrix.size()[2]))\n",
    "        logits = self.label(fc_out)\n",
    "        x = F.log_softmax(logits, dim=1)\n",
    "\n",
    "        return x, attn_weight_matrix\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 10918,
     "status": "ok",
     "timestamp": 1590576493632,
     "user": {
      "displayName": "EZEE MA",
      "photoUrl": "",
      "userId": "17914780779946211373"
     },
     "user_tz": -600
    },
    "id": "fHLFVaQbXUat",
    "outputId": "f33bae75-e68e-4101-9d41-2eb113fb9f37"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\EZEE\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:50: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "  \"num_layers={}\".format(dropout, num_layers))\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "batch_size = None\n",
    "output_size = 2\n",
    "hidden_size = 128\n",
    "vocab_size = len(word_to_ix)\n",
    "embedding_length = 50\n",
    "learning_rate = 0.001\n",
    "epochs = 20\n",
    "model = SelfAttention(batch_size, output_size, hidden_size, vocab_size, embedding_length).to('cuda')\n",
    "\n",
    "device = torch.device(\"cuda\")\n",
    "criterion = nn.NLLLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 618108,
     "status": "ok",
     "timestamp": 1590577424079,
     "user": {
      "displayName": "EZEE MA",
      "photoUrl": "",
      "userId": "17914780779946211373"
     },
     "user_tz": -600
    },
    "id": "Y87u-fqZYVmv",
    "outputId": "4590de29-7099-4a5f-e6ab-c23c554e793e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6990 [00:00<?, ?it/s]C:\\Users\\EZEE\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:1558: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "100%|██████████| 6990/6990 [01:32<00:00, 75.95it/s]\n",
      "  0%|          | 8/6990 [00:00<01:33, 74.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0     loss: 0.628729089126737\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6990/6990 [01:32<00:00, 75.77it/s]\n",
      "  0%|          | 8/6990 [00:00<01:30, 77.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1     loss: 0.38734706294042015\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6990/6990 [01:31<00:00, 76.35it/s]\n",
      "  0%|          | 8/6990 [00:00<01:34, 74.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 2     loss: 0.2073016134198643\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6990/6990 [01:31<00:00, 76.67it/s]\n",
      "  0%|          | 8/6990 [00:00<01:31, 76.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 3     loss: 0.13872823564706102\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6990/6990 [01:31<00:00, 76.68it/s]\n",
      "  0%|          | 8/6990 [00:00<01:34, 74.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 4     loss: 0.06659922273203368\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6990/6990 [01:31<00:00, 76.08it/s]\n",
      "  0%|          | 8/6990 [00:00<01:33, 74.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 5     loss: 0.06339292310935063\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6990/6990 [01:36<00:00, 72.72it/s]\n",
      "  0%|          | 7/6990 [00:00<01:46, 65.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 6     loss: 0.022033525105880223\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6990/6990 [01:55<00:00, 60.35it/s]\n",
      "  0%|          | 7/6990 [00:00<01:51, 62.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 7     loss: 0.018652071913595022\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6990/6990 [01:45<00:00, 66.50it/s]\n",
      "  0%|          | 8/6990 [00:00<01:38, 70.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 8     loss: 0.0771285041420586\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6990/6990 [01:55<00:00, 60.28it/s]\n",
      "  0%|          | 7/6990 [00:00<01:49, 63.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 9     loss: 0.01762780362956002\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6990/6990 [01:57<00:00, 59.60it/s]\n",
      "  0%|          | 8/6990 [00:00<01:37, 71.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 10     loss: 0.015624358661696635\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6990/6990 [01:46<00:00, 65.76it/s]\n",
      "  0%|          | 14/6990 [00:00<01:40, 69.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 11     loss: 0.036622554447517885\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6990/6990 [01:43<00:00, 67.45it/s]\n",
      "  0%|          | 7/6990 [00:00<01:43, 67.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 12     loss: 0.35801907026546026\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6990/6990 [01:44<00:00, 66.93it/s]\n",
      "  0%|          | 6/6990 [00:00<01:59, 58.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 13     loss: 0.29903646829472763\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6990/6990 [01:44<00:00, 67.07it/s]\n",
      "  0%|          | 6/6990 [00:00<01:59, 58.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 14     loss: 0.03254545639683419\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6990/6990 [01:43<00:00, 67.37it/s]\n",
      "  0%|          | 8/6990 [00:00<01:39, 70.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 15     loss: 0.016250193895017983\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6990/6990 [01:43<00:00, 67.40it/s]\n",
      "  0%|          | 8/6990 [00:00<01:37, 71.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 16     loss: 0.014275266650067548\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6990/6990 [01:43<00:00, 67.52it/s]\n",
      "  0%|          | 8/6990 [00:00<01:36, 72.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 17     loss: 2.015253504970043e-05\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6990/6990 [01:43<00:00, 67.27it/s]\n",
      "  0%|          | 7/6990 [00:00<01:44, 66.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 18     loss: 7.56868135946162e-08\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6990/6990 [01:44<00:00, 66.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 19     loss: 3.956588723287733e-08\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "m = len(train_input_index)\n",
    "for epoch in range(epochs):  \n",
    "    losses = []\n",
    "    model.train()\n",
    "    indexes = list(np.random.permutation(m))\n",
    "    for i in tqdm(indexes, position = 0):\n",
    "        tags_index = [train_output_index[i]]\n",
    "        optimizer.zero_grad()\n",
    "        sentence_in = torch.tensor(train_input_index[i], dtype=torch.long).to('cuda')\n",
    "        #print(sentence_in.shape)\n",
    "        targets = torch.tensor(tags_index, dtype=torch.long).to(device)\n",
    "        output, _ = model(sentence_in)  \n",
    "        loss = criterion(output, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        losses.append(loss.item())\n",
    "\n",
    "    losses = np.array(losses)\n",
    "    print('epoch:', epoch, '    loss:', np.mean(losses))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4708,
     "status": "ok",
     "timestamp": 1590579677798,
     "user": {
      "displayName": "EZEE MA",
      "photoUrl": "",
      "userId": "17914780779946211373"
     },
     "user_tz": -600
    },
    "id": "LsInKVbEp18M",
    "outputId": "b061e9e7-3813-4578-9bbf-16700b26d2fd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7232065059541097\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "correctPre = []\n",
    "for i in range(len(val_input_index)):\n",
    "    model.eval()\n",
    "    \n",
    "    \n",
    "    sentence_in = torch.tensor(val_input_index[i], dtype=torch.long).to('cuda')\n",
    "    output, weights = model(sentence_in) \n",
    "    pred = torch.argmax(output, axis = -1).cpu().numpy()[0]\n",
    "    if pred == val_output_index[i]:\n",
    "        correctPre.append(i)\n",
    "        correct += 1\n",
    "print(correct/len(val_input_index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Affin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: afinn in c:\\users\\ezee\\anaconda3\\lib\\site-packages (0.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install afinn\n",
    "from afinn import Afinn\n",
    "afinn = Afinn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def afi(text, target):\n",
    "    dic = {}\n",
    "    ans = []\n",
    "    for w in x_test[idx]:  \n",
    "        dic[w] = afinn.score(w)\n",
    "    if target == 0:\n",
    "        for w in dic:\n",
    "            if dic[w] <= -1: ans.append(w)\n",
    "           \n",
    "    if target == 1:\n",
    "        for w in dic:\n",
    "            if dic[w] >= 1: ans.append(w)\n",
    "    return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexes = []\n",
    "for idx in correctPre:\n",
    "    word = afi(x_test[idx], y_test[idx])  \n",
    "    if len(word) > 0:\n",
    "        indexes.append(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "affin = []\n",
    "for i in indexes[0:50]:\n",
    "    idx = i\n",
    "    word = afi(x_test[idx], y_test[idx])  \n",
    "    #print(word)\n",
    "    affin.append(word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TJCT_TXDavSd"
   },
   "source": [
    "# use self-attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 671,
     "status": "ok",
     "timestamp": 1590582125426,
     "user": {
      "displayName": "EZEE MA",
      "photoUrl": "",
      "userId": "17914780779946211373"
     },
     "user_tz": -600
    },
    "id": "S8gI6sueKSFf",
    "outputId": "98ece8fb-0d53-4524-a5e2-2ec5089743c9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "true label: 1\n",
      "predicted label: 0\n",
      "important features: ['lame', 'art', 'adaptation']\n",
      "original text: b\"it ain't art , by a long shot , but unlike last year's lame musketeer , this dumas adaptation entertains .\"\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "index = 18\n",
    "\n",
    "model.eval()\n",
    "sentence_in = torch.tensor(val_input_index[index], dtype=torch.long).to('cuda')\n",
    "output, weights = model(sentence_in) \n",
    "avg_weight = torch.mean(weights, axis = 1)\n",
    "idx = torch.topk(avg_weight, k = 3)\n",
    "idx = idx.indices.cpu().numpy().tolist()[0]\n",
    "word = [x_test[index][k] for k in idx]\n",
    "pred = torch.argmax(output, axis = -1).cpu().numpy()[0]\n",
    "print(\"true label:\", y_test[index])\n",
    "print('predicted label:', pred)\n",
    "print('important features:', word)\n",
    "print('original text:', x_te[index])\n",
    "print(y_test[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1449,
     "status": "ok",
     "timestamp": 1590582300081,
     "user": {
      "displayName": "EZEE MA",
      "photoUrl": "",
      "userId": "17914780779946211373"
     },
     "user_tz": -600
    },
    "id": "8pdVIb8F8WlC",
    "outputId": "dc3aa255-eab9-4e26-f399-483372574a47"
   },
   "outputs": [],
   "source": [
    "def selfatt(index):\n",
    "    model.eval()\n",
    "    sentence_in = torch.tensor(val_input_index[index], dtype=torch.long).to('cuda')\n",
    "    output, weights = model(sentence_in) \n",
    "    avg_weight = torch.mean(weights, axis = 1)\n",
    "    k = min(sentence_in.shape[0], 5)\n",
    "    idx = torch.topk(avg_weight, k = k)\n",
    "    idx = idx.indices.cpu().numpy().tolist()[0]\n",
    "    word = [x_test[index][k] for k in idx]\n",
    "    return word\n",
    "\n",
    "self_attention = []\n",
    "for index in indexes[0:50]:\n",
    "    words = selfatt(index)\n",
    "    self_attention.append(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Bfm0xISday4q"
   },
   "source": [
    "# use anchor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Qyy9REdQOtFm"
   },
   "outputs": [],
   "source": [
    "def predict_nn(text):\n",
    "    text = clean_sentence(text)\n",
    "    text = to_index(text,word_to_ix)[0]\n",
    "    model.eval()\n",
    "    sentence_in = torch.tensor(text, dtype=torch.long).to('cuda')\n",
    "    output, weights = model(sentence_in) \n",
    "    pred = torch.argmax(output, axis = -1).cpu().numpy()\n",
    "    return pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2085764,
     "status": "ok",
     "timestamp": 1590584439557,
     "user": {
      "displayName": "EZEE MA",
      "photoUrl": "",
      "userId": "17914780779946211373"
     },
     "user_tz": -600
    },
    "id": "HpqYFlqP50iB",
    "outputId": "767344aa-2300-4804-a617-f19288d09f2e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [58:53<00:00, 70.67s/it]   \n"
     ]
    }
   ],
   "source": [
    "def find_anchor(index):\n",
    "    explainer = anchor_text.AnchorText(nlp, ['negative', 'positive'], use_unk_distribution=True)\n",
    "    np.random.seed(1)\n",
    "    text = x_te[index]\n",
    "    pred = explainer.class_names[predict_nn([text])[0]]\n",
    "    alternative =  explainer.class_names[1 - predict_nn([text])[0]]\n",
    "    html = clean_sentence([text])[0]\n",
    "    html = u' '.join(html)\n",
    "    html\n",
    "    exp = explainer.explain_instance(html, predict_nn, threshold=0.995)\n",
    "    return exp.names()\n",
    "\n",
    "anchor = []\n",
    "for index in tqdm(indexes[0:50], position = 0):\n",
    "    word = find_anchor(index)\n",
    "    anchor.append(word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vFYd49Oda1aP"
   },
   "source": [
    "# use LIME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UdsKR6wPa2Xj"
   },
   "outputs": [],
   "source": [
    "import lime\n",
    "from lime import lime_text\n",
    "from lime.lime_text import LimeTextExplainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "M6fLkNL-5gPj"
   },
   "outputs": [],
   "source": [
    "def findprob(text):\n",
    "    text = clean_sentence(text)\n",
    "    prob = []\n",
    "    for i in range(len(text)):\n",
    "        corpus = [word_to_ix[w] for w in text[i]]\n",
    "        sentence_in = torch.tensor([19387]+corpus, dtype=torch.long).to('cuda')\n",
    "        \n",
    "        model.eval()\n",
    "        out, _ = model(sentence_in) \n",
    "        out = out.cpu().detach().numpy()\n",
    "        exp = np.exp(out)\n",
    "        expsum = 0\n",
    "        for i in range(len(exp[0])):\n",
    "            expsum += exp[0][i]\n",
    "        ans = exp/expsum\n",
    "        prob.append(ans[0])\n",
    "    return np.array(prob)\n",
    "\n",
    "#findprob([ x_te[6], x_te[7] ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "af13-UDAbt6M"
   },
   "outputs": [],
   "source": [
    "class_names = ['neg', \"pos\"]\n",
    "explainer = LimeTextExplainer(class_names=class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EFzTvi1OAV8z"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\EZEE\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:1558: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\EZEE\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:1558: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\EZEE\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:1558: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\EZEE\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:1558: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\EZEE\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:1558: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\EZEE\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:1558: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\EZEE\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:1558: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\EZEE\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:1558: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\EZEE\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:1558: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\EZEE\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:1558: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\EZEE\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:1558: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\EZEE\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:1558: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\EZEE\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:1558: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\EZEE\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:1558: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\EZEE\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:1558: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\EZEE\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:1558: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\EZEE\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:1558: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\EZEE\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:1558: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\EZEE\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:1558: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\EZEE\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:1558: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\EZEE\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:1558: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\EZEE\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:1558: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\EZEE\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:1558: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\EZEE\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:1558: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\EZEE\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:1558: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\EZEE\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:1558: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\EZEE\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:1558: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\EZEE\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:1558: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\EZEE\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:1558: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\EZEE\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:1558: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\EZEE\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:1558: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\EZEE\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:1558: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\EZEE\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:1558: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\EZEE\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:1558: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\EZEE\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:1558: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\EZEE\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:1558: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\EZEE\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:1558: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\EZEE\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:1558: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\EZEE\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:1558: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\EZEE\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:1558: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\EZEE\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:1558: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\EZEE\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:1558: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\EZEE\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:1558: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\EZEE\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:1558: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\EZEE\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:1558: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\EZEE\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:1558: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\EZEE\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:1558: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\EZEE\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:1558: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\EZEE\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:1558: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\EZEE\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:1558: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "def findlime(idx):\n",
    "    text = x_te[idx].decode('utf-8')\n",
    "    text = clean_sentence([text])[0]\n",
    "    html = ' '.join(text)\n",
    "    exp = explainer.explain_instance(html ,findprob, num_features=3, top_labels = 1)\n",
    "    label = exp.top_labels[0]\n",
    "    A = [u for (u, v) in exp.local_exp[label]]\n",
    "    B = [text[u] for u in A]\n",
    "    return B\n",
    "\n",
    "lime = []\n",
    "for index in indexes[0:50]:\n",
    "    word = findlime(index)\n",
    "    lime.append(word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7q3qC55wEZhk"
   },
   "source": [
    "# recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lime: 0.41735537190082644\n",
      "anchor: 0.5330578512396694\n"
     ]
    }
   ],
   "source": [
    "def recall(true, pred):\n",
    "    correct = 0\n",
    "    all = 0\n",
    "    for i in range(len(pred)):\n",
    "        all += len(true[i])\n",
    "        for word in pred[i]:\n",
    "            if word in true[i]: correct += 1\n",
    "    return correct/all\n",
    "\n",
    "print('lime:', recall(self_attention, lime))\n",
    "print('anchor:', recall(self_attention, anchor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lime: 0.39473684210526316\n",
      "anchor: 0.6052631578947368\n"
     ]
    }
   ],
   "source": [
    "print('lime:', recall(affin, lime))\n",
    "print('anchor:', recall(affin, anchor))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lime: 0.6778523489932886\n",
      "anchor: 0.524390243902439\n"
     ]
    }
   ],
   "source": [
    "def precision(true, pred):\n",
    "    correct = 0\n",
    "    all = 0\n",
    "    for i in range(len(pred)):\n",
    "        all += len(pred[i])\n",
    "        for word in pred[i]:\n",
    "            if word in true[i]: correct += 1\n",
    "    return correct/all\n",
    "\n",
    "print('lime:', precision(self_attention, lime))\n",
    "print('anchor:', precision(self_attention, anchor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lime: 0.20134228187919462\n",
      "anchor: 0.18699186991869918\n"
     ]
    }
   ],
   "source": [
    "print('lime:', precision(affin, lime))\n",
    "print('anchor:', precision(affin, anchor))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyMoAYAik9Sw6OhXJUNAp8px",
   "name": "Untitled0.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
